{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import statsmodels as sm\n",
    "from sklearn import preprocessing \n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/91908/Desktop/Dream Hokage/Sem-5/Machine Learning/Project/phl_hec_all_confirmed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['P. Max Mass (EU)','P. Surf ESI','P. Int ESI','P. Name KOI','S. Name','S. Name HD','S. Name HIP','P. Min Mass (EU)','P. SPH','P. Ts Max (K)','P. Ts Min (K)','P. Ts Mean (K)','P. Name','P. Name Kepler','P. Teq Min (K)','P. Teq Max (K)','P. Teq Mean (K)','S. Hab Zone Max (AU)','P. Mean Distance (AU)','Unnamed: 68','P. SFlux Min (EU)','P. SFlux Max (EU)'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['P. SFlux Mean (EU)']=pd.to_numeric(df['P. SFlux Mean (EU)'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_var_names=[key for key in dict(df.dtypes) if dict(df.dtypes)[key] in ['float64', 'int64', 'float32', 'int32']]\n",
    "cat_var_names=[key for key in dict(df.dtypes) if dict(df.dtypes)[key] in ['object', 'O']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num=df[numeric_var_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat=df[cat_var_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_summary(x):\n",
    "    mean = x.mean()\n",
    "    sum = x.sum()\n",
    "    std = x.std()\n",
    "    return pd.Series([mean, sum, std], index=['avg', 'total', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Data audit Report\n",
    "# Use a general function that returns multiple values\n",
    "def var_summary(x):\n",
    "    return pd.Series([x.count(), x.isnull().sum(), x.sum(), x.mean(), x.median(),  x.std(), x.var(), x.min(), x.dropna().quantile(0.01), x.dropna().quantile(0.05),x.dropna().quantile(0.10),x.dropna().quantile(0.25),x.dropna().quantile(0.50),x.dropna().quantile(0.75), x.dropna().quantile(0.90),x.dropna().quantile(0.95), x.dropna().quantile(0.99),x.max()], \n",
    "                  index=['N', 'NMISS', 'SUM', 'MEAN','MEDIAN', 'STD', 'VAR','MIN', 'P1' , 'P5' ,'P10' ,'P25' ,'P50' ,'P75' ,'P90' ,'P95' ,'P99' ,'MAX'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_summary=df_num.apply(var_summary).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_summary.to_csv('/Users/91908/Desktop/Dream Hokage/Sem-5/Machine Learning/Project/num_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat=df.select_dtypes(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_summary(x):\n",
    "    return pd.Series([x.count(), x.isnull().sum(), x.value_counts()], \n",
    "                  index=['N', 'NMISS', 'ColumnsNames'])\n",
    "\n",
    "df_summary=df_cat.apply(cat_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P. Mass (EU)</th>\n",
       "      <th>P. Radius (EU)</th>\n",
       "      <th>P. Density (EU)</th>\n",
       "      <th>P. Gravity (EU)</th>\n",
       "      <th>P. Esc Vel (EU)</th>\n",
       "      <th>P. SFlux Mean (EU)</th>\n",
       "      <th>P. Surf Press (EU)</th>\n",
       "      <th>P. Mag</th>\n",
       "      <th>P. Appar Size (deg)</th>\n",
       "      <th>P. Period (days)</th>\n",
       "      <th>...</th>\n",
       "      <th>S. Hab Zone Min (AU)</th>\n",
       "      <th>P. HZD</th>\n",
       "      <th>P. HZC</th>\n",
       "      <th>P. HZA</th>\n",
       "      <th>P. HZI</th>\n",
       "      <th>P. ESI</th>\n",
       "      <th>S. HabCat</th>\n",
       "      <th>P. Habitable</th>\n",
       "      <th>P. Hab Moon</th>\n",
       "      <th>P. Confirmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4451.16</td>\n",
       "      <td>19.04</td>\n",
       "      <td>0.64</td>\n",
       "      <td>12.28</td>\n",
       "      <td>15.29</td>\n",
       "      <td>4.080000e-06</td>\n",
       "      <td>2870.4</td>\n",
       "      <td>-10.06</td>\n",
       "      <td>36.81</td>\n",
       "      <td>12.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.540</td>\n",
       "      <td>800.07</td>\n",
       "      <td>23.51</td>\n",
       "      <td>85.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6358.80</td>\n",
       "      <td>10.94</td>\n",
       "      <td>4.86</td>\n",
       "      <td>53.12</td>\n",
       "      <td>24.11</td>\n",
       "      <td>2.166914e-02</td>\n",
       "      <td>30873.8</td>\n",
       "      <td>-18.21</td>\n",
       "      <td>20.91</td>\n",
       "      <td>3725.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461</td>\n",
       "      <td>9.07</td>\n",
       "      <td>15.30</td>\n",
       "      <td>45.41</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4133.22</td>\n",
       "      <td>11.40</td>\n",
       "      <td>2.79</td>\n",
       "      <td>31.79</td>\n",
       "      <td>19.04</td>\n",
       "      <td>3.960000e-06</td>\n",
       "      <td>11520.8</td>\n",
       "      <td>-8.91</td>\n",
       "      <td>21.80</td>\n",
       "      <td>12.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136</td>\n",
       "      <td>793.67</td>\n",
       "      <td>12.57</td>\n",
       "      <td>107.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6358.80</td>\n",
       "      <td>11.20</td>\n",
       "      <td>4.53</td>\n",
       "      <td>50.69</td>\n",
       "      <td>23.83</td>\n",
       "      <td>1.030000e-05</td>\n",
       "      <td>28780.4</td>\n",
       "      <td>-9.92</td>\n",
       "      <td>21.41</td>\n",
       "      <td>12.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136</td>\n",
       "      <td>490.45</td>\n",
       "      <td>15.72</td>\n",
       "      <td>119.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4419.37</td>\n",
       "      <td>16.13</td>\n",
       "      <td>1.05</td>\n",
       "      <td>16.99</td>\n",
       "      <td>16.55</td>\n",
       "      <td>2.370000e-07</td>\n",
       "      <td>4655.6</td>\n",
       "      <td>-6.60</td>\n",
       "      <td>31.03</td>\n",
       "      <td>12.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062</td>\n",
       "      <td>3028.82</td>\n",
       "      <td>19.46</td>\n",
       "      <td>133.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   P. Mass (EU)  P. Radius (EU)  P. Density (EU)  P. Gravity (EU)  \\\n",
       "0       4451.16           19.04             0.64            12.28   \n",
       "1       6358.80           10.94             4.86            53.12   \n",
       "2       4133.22           11.40             2.79            31.79   \n",
       "3       6358.80           11.20             4.53            50.69   \n",
       "4       4419.37           16.13             1.05            16.99   \n",
       "\n",
       "   P. Esc Vel (EU)  P. SFlux Mean (EU)  P. Surf Press (EU)  P. Mag  \\\n",
       "0            15.29        4.080000e-06              2870.4  -10.06   \n",
       "1            24.11        2.166914e-02             30873.8  -18.21   \n",
       "2            19.04        3.960000e-06             11520.8   -8.91   \n",
       "3            23.83        1.030000e-05             28780.4   -9.92   \n",
       "4            16.55        2.370000e-07              4655.6   -6.60   \n",
       "\n",
       "   P. Appar Size (deg)  P. Period (days)  ...  S. Hab Zone Min (AU)   P. HZD  \\\n",
       "0                36.81              12.9  ...                 0.540   800.07   \n",
       "1                20.91            3725.0  ...                 0.461     9.07   \n",
       "2                21.80              12.9  ...                 0.136   793.67   \n",
       "3                21.41              12.9  ...                 0.136   490.45   \n",
       "4                31.03              12.9  ...                 0.062  3028.82   \n",
       "\n",
       "   P. HZC  P. HZA  P. HZI  P. ESI  S. HabCat  P. Habitable  P. Hab Moon  \\\n",
       "0   23.51   85.62    0.00    0.05          0             0            0   \n",
       "1   15.30   45.41    0.02    0.07          0             0            0   \n",
       "2   12.57  107.44    0.00    0.06          0             0            0   \n",
       "3   15.72  119.46    0.00    0.08          0             0            0   \n",
       "4   19.46  133.25    0.00    0.06          0             0            0   \n",
       "\n",
       "   P. Confirmed  \n",
       "0             1  \n",
       "1             1  \n",
       "2             1  \n",
       "3             1  \n",
       "4             1  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Handling missings \n",
    "def Missing_imputation(x):\n",
    "    x = x.fillna(x.median())\n",
    "    return x\n",
    "\n",
    "df_num=df_num.apply(Missing_imputation)\n",
    "\n",
    "num_summary=df_num.apply(var_summary).T\n",
    "num_summary\n",
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91908\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: clip_upper(threshold) is deprecated, use clip(upper=threshold) instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\91908\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: clip_lower(threshold) is deprecated, use clip(lower=threshold) instead\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Handling Outliers \n",
    "def outlier_capping(x):\n",
    "    x = x.clip_upper(x.quantile(0.99))\n",
    "    x = x.clip_lower(x.quantile(0.01))\n",
    "    return x\n",
    "\n",
    "df_num=df_num.apply(outlier_capping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " def create_dummies( df, colname ):\n",
    "     col_dummies = pd.get_dummies(df[colname], prefix=colname, drop_first=True)\n",
    "     df = pd.concat([df, col_dummies], axis=1)\n",
    "     df.drop( colname, axis = 1, inplace = True )\n",
    "     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91908\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for c_feature in ['P. Mass Class', 'P. Composition Class','P. Disc. Method','S. Constellation','P. Zone Class','P. Atmosphere Class']:\n",
    "     df_cat[c_feature] = df_cat[c_feature].astype('category')\n",
    "     df_cat = create_dummies(df_cat , c_feature )\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat['S. Type']= df_cat['S. Type'].astype('str') \n",
    "df_cat['S. Type']= label_encoder.fit_transform(df_cat['S. Type'])\n",
    "df_cat['P. Disc. Year']= label_encoder.fit_transform(df_cat['P. Disc. Year']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.concat([df_num,df_cat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('/Users/91908/Desktop/Dream Hokage/Sem-5/Machine Learning/Project/data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new1=df_new\n",
    "df_new1.shape\n",
    "df_new1.columns = df_new1.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3875, 151)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new1.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, test_size):\n",
    "    \n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "\n",
    "    indices = df.index.tolist()\n",
    "    test_indices = random.sample(population=indices, k=test_size)\n",
    "\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df_new1, test_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new1.iloc[:,43]#target class\n",
    "cols = df_new1.columns.tolist()\n",
    "cols=['P.Mass(EU)',\n",
    " 'P.Radius(EU)',\n",
    " 'P.Density(EU)',\n",
    " 'P.Gravity(EU)',\n",
    " 'P.EscVel(EU)',\n",
    " 'P.SFluxMean(EU)',\n",
    " 'P.SurfPress(EU)',\n",
    " 'P.Mag',\n",
    " 'P.ApparSize(deg)',\n",
    " 'P.Period(days)',\n",
    " 'P.SemMajorAxis(AU)',\n",
    " 'P.Eccentricity',\n",
    " 'P.Inclination(deg)',\n",
    " 'P.Omega(deg)',\n",
    " 'S.Mass(SU)',\n",
    " 'S.Radius(SU)',\n",
    " 'S.Teff(K)',\n",
    " 'S.Luminosity(SU)',\n",
    " 'S.[Fe/H]',\n",
    " 'S.Age(Gyrs)',\n",
    " 'S.ApparMag',\n",
    " 'S.Distance(pc)',\n",
    " 'S.RA(hrs)',\n",
    " 'S.DEC(deg)',\n",
    " 'S.MagfromPlanet',\n",
    " 'S.SizefromPlanet(deg)',\n",
    " 'S.No.Planets',\n",
    " 'S.No.PlanetsHZ',\n",
    " 'S.HabZoneMin(AU)',\n",
    " 'P.HZD',\n",
    " 'P.HZC',\n",
    " 'P.HZA',\n",
    " 'P.HZI',\n",
    " 'P.ESI',\n",
    " 'S.HabCat',\n",
    " 'P.Habitable',\n",
    " 'P.HabMoon',\n",
    " 'P.Confirmed',\n",
    " 'P.AtmosphereClass_no-atmosphere',\n",
    " 'S.Type',\n",
    " 'P.Disc.Year',\n",
    " 'P.MassClass_Mercurian',\n",
    " 'P.MassClass_Neptunian',\n",
    " 'P.MassClass_Subterran',\n",
    " 'P.MassClass_Superterran',\n",
    " 'P.MassClass_Terran',\n",
    " 'P.CompositionClass_iron',\n",
    " 'P.CompositionClass_rocky-iron',\n",
    " 'P.CompositionClass_rocky-water',\n",
    " 'P.CompositionClass_water-gas',\n",
    " 'P.Disc.Method_Imaging',\n",
    " 'P.Disc.Method_Microlensing',\n",
    " 'P.Disc.Method_Other',\n",
    " 'P.Disc.Method_PrimaryTransit',\n",
    " 'P.Disc.Method_Pulsar',\n",
    " 'P.Disc.Method_RadialVelocity',\n",
    " 'P.Disc.Method_TTV',\n",
    " 'P.Disc.Method_Transit',\n",
    " 'P.Disc.Method_radialvelocity',\n",
    " 'P.Disc.Method_transit',\n",
    " 'S.Constellation_Ant',\n",
    " 'S.Constellation_Aps',\n",
    " 'S.Constellation_Aql',\n",
    " 'S.Constellation_Aqr',\n",
    " 'S.Constellation_Ara',\n",
    " 'S.Constellation_Ari',\n",
    " 'S.Constellation_Aur',\n",
    " 'S.Constellation_Boo',\n",
    " 'S.Constellation_CMa',\n",
    " 'S.Constellation_CMi',\n",
    " 'S.Constellation_CVn',\n",
    " 'S.Constellation_Cae',\n",
    " 'S.Constellation_Cam',\n",
    " 'S.Constellation_Cap',\n",
    " 'S.Constellation_Car',\n",
    " 'S.Constellation_Cas',\n",
    " 'S.Constellation_Cen',\n",
    " 'S.Constellation_Cep',\n",
    " 'S.Constellation_Cet',\n",
    " 'S.Constellation_Cha',\n",
    " 'S.Constellation_Cir',\n",
    " 'S.Constellation_Cnc',\n",
    " 'S.Constellation_Col',\n",
    " 'S.Constellation_Com',\n",
    " 'S.Constellation_CrA',\n",
    " 'S.Constellation_CrB',\n",
    " 'S.Constellation_Crt',\n",
    " 'S.Constellation_Cru',\n",
    " 'S.Constellation_Crv',\n",
    " 'S.Constellation_Cyg',\n",
    " 'S.Constellation_Del',\n",
    " 'S.Constellation_Dor',\n",
    " 'S.Constellation_Dra',\n",
    " 'S.Constellation_Equ',\n",
    " 'S.Constellation_Eri',\n",
    " 'S.Constellation_For',\n",
    " 'S.Constellation_Gem',\n",
    " 'S.Constellation_Gru',\n",
    " 'S.Constellation_Her',\n",
    " 'S.Constellation_Hor',\n",
    " 'S.Constellation_Hya',\n",
    " 'S.Constellation_Hyi',\n",
    " 'S.Constellation_Ind',\n",
    " 'S.Constellation_LMi',\n",
    " 'S.Constellation_Lac',\n",
    " 'S.Constellation_Leo',\n",
    " 'S.Constellation_Lep',\n",
    " 'S.Constellation_Lib',\n",
    " 'S.Constellation_Lup',\n",
    " 'S.Constellation_Lyn',\n",
    " 'S.Constellation_Lyr',\n",
    " 'S.Constellation_Men',\n",
    " 'S.Constellation_Mic',\n",
    " 'S.Constellation_Mon',\n",
    " 'S.Constellation_Mus',\n",
    " 'S.Constellation_Nor',\n",
    " 'S.Constellation_Oct',\n",
    " 'S.Constellation_Oph',\n",
    " 'S.Constellation_Ori',\n",
    " 'S.Constellation_Pav',\n",
    " 'S.Constellation_Peg',\n",
    " 'S.Constellation_Per',\n",
    " 'S.Constellation_Phe',\n",
    " 'S.Constellation_Pic',\n",
    " 'S.Constellation_PsA',\n",
    " 'S.Constellation_Psc',\n",
    " 'S.Constellation_Pup',\n",
    " 'S.Constellation_Pyx',\n",
    " 'S.Constellation_Ret',\n",
    " 'S.Constellation_Scl',\n",
    " 'S.Constellation_Sco',\n",
    " 'S.Constellation_Sct',\n",
    " 'S.Constellation_Ser',\n",
    " 'S.Constellation_Sex',\n",
    " 'S.Constellation_Sge',\n",
    " 'S.Constellation_Sgr',\n",
    " 'S.Constellation_Tau',\n",
    " 'S.Constellation_Tel',\n",
    " 'S.Constellation_TrA',\n",
    " 'S.Constellation_Tri',\n",
    " 'S.Constellation_Tuc',\n",
    " 'S.Constellation_UMa',\n",
    " 'S.Constellation_UMi',\n",
    " 'S.Constellation_Vel',\n",
    " 'S.Constellation_Vir',\n",
    " 'S.Constellation_Vol',\n",
    " 'S.Constellation_Vul',\n",
    " 'P.ZoneClass_Hot',\n",
    " 'P.ZoneClass_Warm',\n",
    " 'P.AtmosphereClass_metals-rich',\n",
    "'P.HabitableClass']\n",
    "\n",
    "df_new1=df_new1[cols]\n",
    "#df_new1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(data):   \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    index = counts_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(data):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    for column_index in range(n_columns - 1):        # excluding the last column which is the label\n",
    "        potential_splits[column_index] = []\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "        #print(unique_values)\n",
    "        for index in range(len(unique_values)):\n",
    "            if index != 0:\n",
    "                current_value = unique_values[index]\n",
    "                previous_value = unique_values[index - 1]\n",
    "                #print(current_value)\n",
    "                #print(previous_value)\n",
    "                potential_split = (int(current_value)+ int(previous_value)) / 2\n",
    "                \n",
    "                potential_splits[column_index].append(potential_split)\n",
    "    \n",
    "    return potential_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, split_column, split_value):\n",
    "    \n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    data_below = data[split_column_values <= split_value]\n",
    "    data_above = data[split_column_values >  split_value]\n",
    "    \n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "     \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(data_below, data_above):\n",
    "    \n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    overall_entropy =  (p_data_below * calculate_entropy(data_below) \n",
    "                      + p_data_above * calculate_entropy(data_above))\n",
    "    \n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(data, potential_splits):\n",
    "    \n",
    "    overall_entropy = 9999\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_type_of_feature(df):\n",
    "    \n",
    "    feature_types = []\n",
    "    n_unique_values_treshold = 15\n",
    "    for feature in df.columns:\n",
    "        if feature != \"label\":\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0]\n",
    "\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "    \n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, counter=0, min_samples=2, max_depth=5):\n",
    "    \n",
    "    # data preparations\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS, FEATURE_TYPES\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        FEATURE_TYPES = determine_type_of_feature(df)\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df           \n",
    "    \n",
    "    \n",
    "    # base cases\n",
    "    if (check_purity(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
    "        classification = classify_data(data)\n",
    "        \n",
    "        return classification\n",
    "\n",
    "    \n",
    "    # recursive part\n",
    "    else:    \n",
    "        counter += 1\n",
    "\n",
    "        # helper functions \n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = determine_best_split(data, potential_splits)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        \n",
    "        # determine question\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        type_of_feature = FEATURE_TYPES[split_column]\n",
    "        if type_of_feature == \"continuous\":\n",
    "            question = \"{} <= {}\".format(feature_name, split_value)\n",
    "            \n",
    "        # feature is categorical\n",
    "        else:\n",
    "            question = \"{} = {}\".format(feature_name, split_value)\n",
    "        \n",
    "        # instantiate sub-tree\n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        # find answers (recursion)\n",
    "        yes_answer = decision_tree_algorithm(data_below, counter, min_samples, max_depth)\n",
    "        no_answer = decision_tree_algorithm(data_above, counter, min_samples, max_depth)\n",
    "        \n",
    "        # If the answers are the same, then there is no point in asking the qestion.\n",
    "        # This could happen when the data is classified even though it is not pure\n",
    "        # yet (min_samples or max_depth base case).\n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()\n",
    "cols = train_df.columns.tolist()\n",
    "cols=['P.Mass(EU)',\n",
    " 'P.Radius(EU)',\n",
    " 'P.Density(EU)',\n",
    " 'P.Gravity(EU)',\n",
    " 'P.EscVel(EU)',\n",
    " 'P.SFluxMean(EU)',\n",
    " 'P.SurfPress(EU)',\n",
    " 'P.Mag',\n",
    " 'P.ApparSize(deg)',\n",
    " 'P.Period(days)',\n",
    " 'P.SemMajorAxis(AU)',\n",
    " 'P.Eccentricity',\n",
    " 'P.Inclination(deg)',\n",
    " 'P.Omega(deg)',\n",
    " 'S.Mass(SU)',\n",
    " 'S.Radius(SU)',\n",
    " 'S.Teff(K)',\n",
    " 'S.Luminosity(SU)',\n",
    " 'S.[Fe/H]',\n",
    " 'S.Age(Gyrs)',\n",
    " 'S.ApparMag',\n",
    " 'S.Distance(pc)',\n",
    " 'S.RA(hrs)',\n",
    " 'S.DEC(deg)',\n",
    " 'S.MagfromPlanet',\n",
    " 'S.SizefromPlanet(deg)',\n",
    " 'S.No.Planets',\n",
    " 'S.No.PlanetsHZ',\n",
    " 'S.HabZoneMin(AU)',\n",
    " 'P.HZD',\n",
    " 'P.HZC',\n",
    " 'P.HZA',\n",
    " 'P.HZI',\n",
    " 'P.ESI',\n",
    " 'S.HabCat',\n",
    " 'P.Habitable',\n",
    " 'P.HabMoon',\n",
    " 'P.Confirmed',\n",
    " 'P.AtmosphereClass_no-atmosphere',\n",
    " 'S.Type',\n",
    " 'P.Disc.Year',\n",
    " 'P.MassClass_Mercurian',\n",
    " 'P.MassClass_Neptunian',\n",
    " 'P.MassClass_Subterran',\n",
    " 'P.MassClass_Superterran',\n",
    " 'P.MassClass_Terran',\n",
    " 'P.CompositionClass_iron',\n",
    " 'P.CompositionClass_rocky-iron',\n",
    " 'P.CompositionClass_rocky-water',\n",
    " 'P.CompositionClass_water-gas',\n",
    " 'P.Disc.Method_Imaging',\n",
    " 'P.Disc.Method_Microlensing',\n",
    " 'P.Disc.Method_Other',\n",
    " 'P.Disc.Method_PrimaryTransit',\n",
    " 'P.Disc.Method_Pulsar',\n",
    " 'P.Disc.Method_RadialVelocity',\n",
    " 'P.Disc.Method_TTV',\n",
    " 'P.Disc.Method_Transit',\n",
    " 'P.Disc.Method_radialvelocity',\n",
    " 'P.Disc.Method_transit',\n",
    " 'S.Constellation_Ant',\n",
    " 'S.Constellation_Aps',\n",
    " 'S.Constellation_Aql',\n",
    " 'S.Constellation_Aqr',\n",
    " 'S.Constellation_Ara',\n",
    " 'S.Constellation_Ari',\n",
    " 'S.Constellation_Aur',\n",
    " 'S.Constellation_Boo',\n",
    " 'S.Constellation_CMa',\n",
    " 'S.Constellation_CMi',\n",
    " 'S.Constellation_CVn',\n",
    " 'S.Constellation_Cae',\n",
    " 'S.Constellation_Cam',\n",
    " 'S.Constellation_Cap',\n",
    " 'S.Constellation_Car',\n",
    " 'S.Constellation_Cas',\n",
    " 'S.Constellation_Cen',\n",
    " 'S.Constellation_Cep',\n",
    " 'S.Constellation_Cet',\n",
    " 'S.Constellation_Cha',\n",
    " 'S.Constellation_Cir',\n",
    " 'S.Constellation_Cnc',\n",
    " 'S.Constellation_Col',\n",
    " 'S.Constellation_Com',\n",
    " 'S.Constellation_CrA',\n",
    " 'S.Constellation_CrB',\n",
    " 'S.Constellation_Crt',\n",
    " 'S.Constellation_Cru',\n",
    " 'S.Constellation_Crv',\n",
    " 'S.Constellation_Cyg',\n",
    " 'S.Constellation_Del',\n",
    " 'S.Constellation_Dor',\n",
    " 'S.Constellation_Dra',\n",
    " 'S.Constellation_Equ',\n",
    " 'S.Constellation_Eri',\n",
    " 'S.Constellation_For',\n",
    " 'S.Constellation_Gem',\n",
    " 'S.Constellation_Gru',\n",
    " 'S.Constellation_Her',\n",
    " 'S.Constellation_Hor',\n",
    " 'S.Constellation_Hya',\n",
    " 'S.Constellation_Hyi',\n",
    " 'S.Constellation_Ind',\n",
    " 'S.Constellation_LMi',\n",
    " 'S.Constellation_Lac',\n",
    " 'S.Constellation_Leo',\n",
    " 'S.Constellation_Lep',\n",
    " 'S.Constellation_Lib',\n",
    " 'S.Constellation_Lup',\n",
    " 'S.Constellation_Lyn',\n",
    " 'S.Constellation_Lyr',\n",
    " 'S.Constellation_Men',\n",
    " 'S.Constellation_Mic',\n",
    " 'S.Constellation_Mon',\n",
    " 'S.Constellation_Mus',\n",
    " 'S.Constellation_Nor',\n",
    " 'S.Constellation_Oct',\n",
    " 'S.Constellation_Oph',\n",
    " 'S.Constellation_Ori',\n",
    " 'S.Constellation_Pav',\n",
    " 'S.Constellation_Peg',\n",
    " 'S.Constellation_Per',\n",
    " 'S.Constellation_Phe',\n",
    " 'S.Constellation_Pic',\n",
    " 'S.Constellation_PsA',\n",
    " 'S.Constellation_Psc',\n",
    " 'S.Constellation_Pup',\n",
    " 'S.Constellation_Pyx',\n",
    " 'S.Constellation_Ret',\n",
    " 'S.Constellation_Scl',\n",
    " 'S.Constellation_Sco',\n",
    " 'S.Constellation_Sct',\n",
    " 'S.Constellation_Ser',\n",
    " 'S.Constellation_Sex',\n",
    " 'S.Constellation_Sge',\n",
    " 'S.Constellation_Sgr',\n",
    " 'S.Constellation_Tau',\n",
    " 'S.Constellation_Tel',\n",
    " 'S.Constellation_TrA',\n",
    " 'S.Constellation_Tri',\n",
    " 'S.Constellation_Tuc',\n",
    " 'S.Constellation_UMa',\n",
    " 'S.Constellation_UMi',\n",
    " 'S.Constellation_Vel',\n",
    " 'S.Constellation_Vir',\n",
    " 'S.Constellation_Vol',\n",
    " 'S.Constellation_Vul',\n",
    " 'P.ZoneClass_Hot',\n",
    " 'P.ZoneClass_Warm',\n",
    " 'P.AtmosphereClass_metals-rich',\n",
    "'P.HabitableClass']\n",
    "train_df=train_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = decision_tree_algorithm(train_df, max_depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = test_df.columns.tolist()\n",
    "cols=['P.Mass(EU)',\n",
    " 'P.Radius(EU)',\n",
    " 'P.Density(EU)',\n",
    " 'P.Gravity(EU)',\n",
    " 'P.EscVel(EU)',\n",
    " 'P.SFluxMean(EU)',\n",
    " 'P.SurfPress(EU)',\n",
    " 'P.Mag',\n",
    " 'P.ApparSize(deg)',\n",
    " 'P.Period(days)',\n",
    " 'P.SemMajorAxis(AU)',\n",
    " 'P.Eccentricity',\n",
    " 'P.Inclination(deg)',\n",
    " 'P.Omega(deg)',\n",
    " 'S.Mass(SU)',\n",
    " 'S.Radius(SU)',\n",
    " 'S.Teff(K)',\n",
    " 'S.Luminosity(SU)',\n",
    " 'S.[Fe/H]',\n",
    " 'S.Age(Gyrs)',\n",
    " 'S.ApparMag',\n",
    " 'S.Distance(pc)',\n",
    " 'S.RA(hrs)',\n",
    " 'S.DEC(deg)',\n",
    " 'S.MagfromPlanet',\n",
    " 'S.SizefromPlanet(deg)',\n",
    " 'S.No.Planets',\n",
    " 'S.No.PlanetsHZ',\n",
    " 'S.HabZoneMin(AU)',\n",
    " 'P.HZD',\n",
    " 'P.HZC',\n",
    " 'P.HZA',\n",
    " 'P.HZI',\n",
    " 'P.ESI',\n",
    " 'S.HabCat',\n",
    " 'P.Habitable',\n",
    " 'P.HabMoon',\n",
    " 'P.Confirmed',\n",
    " 'P.AtmosphereClass_no-atmosphere',\n",
    " 'S.Type',\n",
    " 'P.Disc.Year',\n",
    " 'P.MassClass_Mercurian',\n",
    " 'P.MassClass_Neptunian',\n",
    " 'P.MassClass_Subterran',\n",
    " 'P.MassClass_Superterran',\n",
    " 'P.MassClass_Terran',\n",
    " 'P.CompositionClass_iron',\n",
    " 'P.CompositionClass_rocky-iron',\n",
    " 'P.CompositionClass_rocky-water',\n",
    " 'P.CompositionClass_water-gas',\n",
    " 'P.Disc.Method_Imaging',\n",
    " 'P.Disc.Method_Microlensing',\n",
    " 'P.Disc.Method_Other',\n",
    " 'P.Disc.Method_PrimaryTransit',\n",
    " 'P.Disc.Method_Pulsar',\n",
    " 'P.Disc.Method_RadialVelocity',\n",
    " 'P.Disc.Method_TTV',\n",
    " 'P.Disc.Method_Transit',\n",
    " 'P.Disc.Method_radialvelocity',\n",
    " 'P.Disc.Method_transit',\n",
    " 'S.Constellation_Ant',\n",
    " 'S.Constellation_Aps',\n",
    " 'S.Constellation_Aql',\n",
    " 'S.Constellation_Aqr',\n",
    " 'S.Constellation_Ara',\n",
    " 'S.Constellation_Ari',\n",
    " 'S.Constellation_Aur',\n",
    " 'S.Constellation_Boo',\n",
    " 'S.Constellation_CMa',\n",
    " 'S.Constellation_CMi',\n",
    " 'S.Constellation_CVn',\n",
    " 'S.Constellation_Cae',\n",
    " 'S.Constellation_Cam',\n",
    " 'S.Constellation_Cap',\n",
    " 'S.Constellation_Car',\n",
    " 'S.Constellation_Cas',\n",
    " 'S.Constellation_Cen',\n",
    " 'S.Constellation_Cep',\n",
    " 'S.Constellation_Cet',\n",
    " 'S.Constellation_Cha',\n",
    " 'S.Constellation_Cir',\n",
    " 'S.Constellation_Cnc',\n",
    " 'S.Constellation_Col',\n",
    " 'S.Constellation_Com',\n",
    " 'S.Constellation_CrA',\n",
    " 'S.Constellation_CrB',\n",
    " 'S.Constellation_Crt',\n",
    " 'S.Constellation_Cru',\n",
    " 'S.Constellation_Crv',\n",
    " 'S.Constellation_Cyg',\n",
    " 'S.Constellation_Del',\n",
    " 'S.Constellation_Dor',\n",
    " 'S.Constellation_Dra',\n",
    " 'S.Constellation_Equ',\n",
    " 'S.Constellation_Eri',\n",
    " 'S.Constellation_For',\n",
    " 'S.Constellation_Gem',\n",
    " 'S.Constellation_Gru',\n",
    " 'S.Constellation_Her',\n",
    " 'S.Constellation_Hor',\n",
    " 'S.Constellation_Hya',\n",
    " 'S.Constellation_Hyi',\n",
    " 'S.Constellation_Ind',\n",
    " 'S.Constellation_LMi',\n",
    " 'S.Constellation_Lac',\n",
    " 'S.Constellation_Leo',\n",
    " 'S.Constellation_Lep',\n",
    " 'S.Constellation_Lib',\n",
    " 'S.Constellation_Lup',\n",
    " 'S.Constellation_Lyn',\n",
    " 'S.Constellation_Lyr',\n",
    " 'S.Constellation_Men',\n",
    " 'S.Constellation_Mic',\n",
    " 'S.Constellation_Mon',\n",
    " 'S.Constellation_Mus',\n",
    " 'S.Constellation_Nor',\n",
    " 'S.Constellation_Oct',\n",
    " 'S.Constellation_Oph',\n",
    " 'S.Constellation_Ori',\n",
    " 'S.Constellation_Pav',\n",
    " 'S.Constellation_Peg',\n",
    " 'S.Constellation_Per',\n",
    " 'S.Constellation_Phe',\n",
    " 'S.Constellation_Pic',\n",
    " 'S.Constellation_PsA',\n",
    " 'S.Constellation_Psc',\n",
    " 'S.Constellation_Pup',\n",
    " 'S.Constellation_Pyx',\n",
    " 'S.Constellation_Ret',\n",
    " 'S.Constellation_Scl',\n",
    " 'S.Constellation_Sco',\n",
    " 'S.Constellation_Sct',\n",
    " 'S.Constellation_Ser',\n",
    " 'S.Constellation_Sex',\n",
    " 'S.Constellation_Sge',\n",
    " 'S.Constellation_Sgr',\n",
    " 'S.Constellation_Tau',\n",
    " 'S.Constellation_Tel',\n",
    " 'S.Constellation_TrA',\n",
    " 'S.Constellation_Tri',\n",
    " 'S.Constellation_Tuc',\n",
    " 'S.Constellation_UMa',\n",
    " 'S.Constellation_UMi',\n",
    " 'S.Constellation_Vel',\n",
    " 'S.Constellation_Vir',\n",
    " 'S.Constellation_Vol',\n",
    " 'S.Constellation_Vul',\n",
    " 'P.ZoneClass_Hot',\n",
    " 'P.ZoneClass_Warm',\n",
    " 'P.AtmosphereClass_metals-rich',\n",
    "'P.HabitableClass']\n",
    "test_df=test_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"/Users/91908/Desktop/Dream Hokage/Sem-5/Machine Learning/Project/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = test_df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classify_example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-7b45e1192f85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclassi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mclassi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassify_example\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mclassi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classify_example' is not defined"
     ]
    }
   ],
   "source": [
    "classi=[]\n",
    "for i in range(0,test_df.shape[0]):\n",
    "    classi.append(classify_example(test_df.iloc[i],tree))\n",
    "classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    #print(question) format P. Habitable = 0.5\n",
    "    feature_name,comparison_operator,value = question.split(\" \")\n",
    "\n",
    "    # ask question\n",
    "    if example[feature_name] <= float(value):\n",
    "        answer = tree[question][0]\n",
    "    else:\n",
    "        answer = tree[question][1]\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classify_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df, tree):\n",
    "\n",
    "    df[\"classification\"] = df.apply(classify_example, axis=1, args=(tree,))\n",
    "    df[\"classification_correct\"] = df[\"classification\"] == df[\"P.HabitableClass\"]\n",
    "    \n",
    "    accuracy = df[\"classification_correct\"].mean()*100\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(test_df, tree)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'S.Constellation_Cen = 0.5': ['psychroplanet',\n",
       "   {'P.AtmosphereClass_metals-rich = 0.5': ['mesoplanet', 'psychroplanet']}]},\n",
       " {'S.Constellation_Sco = 0.5': ['hypopsychroplanet', 'psychroplanet']}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree['P.Habitable = 0.5'][1]['S.MagfromPlanet <= -26.5'][1]['S.MagfromPlanet <= -25.5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "\n",
    "menu = {'dinner':\n",
    "            {'chicken':'good',\n",
    "             'beef':'average',\n",
    "             'vegetarian':{\n",
    "                   'tofu':'good',\n",
    "                   'salad':{\n",
    "                            'caeser':'bad',\n",
    "                            'italian':'average'}\n",
    "                   },\n",
    "             'pork':'bad'}\n",
    "        }\n",
    "\n",
    "def draw(parent_name, child_name):\n",
    "    edge = pydot.Edge(parent_name, child_name)\n",
    "    graph.add_edge(edge)\n",
    "\n",
    "def visit(node, parent=None):\n",
    "    for k,v in node.items():\n",
    "        if isinstance(v, dict):\n",
    "            # We start with the root node whose parent is None\n",
    "            # we don't want to graph the None node\n",
    "            if parent:\n",
    "                draw(parent, k)\n",
    "            visit(v, k)\n",
    "        else:\n",
    "            print(draw(parent, k))\n",
    "            # drawing the label using a distinct name\n",
    "            print(draw(k, k+'_'+v))\n",
    "\n",
    "graph = pydot.Dot(graph_type='graph')\n",
    "visit(menu)\n",
    "graph.write_png('example1_graph.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
